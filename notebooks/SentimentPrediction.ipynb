{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-pretrained-bert --quiet\n",
        "!pip install mlflow --quiet\n",
        "!pip install pyngrok --quiet\n",
        "!pip install importlib-metadata --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXX4_QLH4KBL",
        "outputId": "b2003aed-fc43-4d7b-cf3d-f7d0011a267c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The pycodestyle_magic extension is already loaded. To reload it, use:\n",
            "  %reload_ext pycodestyle_magic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import random as rn\n",
        "import pandas as pd\n",
        "import torch\n",
        "from pytorch_pretrained_bert import BertModel\n",
        "from torch import nn\n",
        "\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.utils.data import RandomSampler, SequentialSampler\n",
        "from torch.optim import Adam\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# mlflow\n",
        "import mlflow\n",
        "from mlflow import log_metric, log_param, log_artifact\n",
        "from pyngrok import ngrok\n",
        "from getpass import getpass\n",
        "\n",
        "# Set random seed for reproducible experiments\n",
        "SEED = 123\n",
        "rn.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "trusted": true,
        "id": "hsmNXOzN3vMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85806d54-ca89-4a53-ec4d-e9f6b9781c9c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pycodestyle:36:1: W391 blank line at end of file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHe5M2Yx47N4",
        "outputId": "b66ae33d-8e97-48d5-bd86-1844d60f58cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzf /content/gdrive/MyDrive/TAED2/aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "id": "zgWwglUy4-hR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data_train = []\n",
        "raw_data_test = []\n",
        "\n",
        "for folder in ['train', 'test']:\n",
        "    path = 'aclImdb/'+folder\n",
        "    for sentiment in ['pos', 'neg']:\n",
        "        directory = path+'/'+sentiment\n",
        "        for filename in os.listdir(directory):\n",
        "            with open(os.path.join(directory, filename)) as f:\n",
        "                lines = f.readlines()\n",
        "                assert len(lines) == 1\n",
        "                if folder == 'train':\n",
        "                    raw_data_train.append({'text':lines[0], 'sentiment':sentiment})\n",
        "                else:\n",
        "                    raw_data_test.append({'text':lines[0], 'sentiment':sentiment})"
      ],
      "metadata": {
        "id": "Ee08_ZBG5GLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, train_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), raw_data_train)))\n",
        "test_texts, test_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), raw_data_test)))\n",
        "\n",
        "len(train_texts), len(train_labels), len(test_texts), len(test_labels)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t9Le3o73vMb",
        "outputId": "da8610c4-02af-462e-c3dc-3000427bcfc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000, 25000, 25000)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37X1FbvO3vMd",
        "outputId": "954d1841-5cc2-4153-99ae-0764a01a511a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 13423489.09B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], train_texts))\n",
        "test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], test_texts))\n",
        "\n",
        "len(train_tokens), len(test_tokens)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r50Ykfx53vMf",
        "outputId": "b49281ab-4bac-4677-d598-990eef15d5fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, train_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "test_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, test_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "\n",
        "train_tokens_ids.shape, test_tokens_ids.shape"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_35psxr3vMg",
        "outputId": "34f7f50e-aaab-4ebb-e804-973fbd44e549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000, 512), (25000, 512))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = np.array(train_labels) == 'pos'\n",
        "test_y = np.array(test_labels) == 'pos'\n",
        "train_y.shape, test_y.shape, np.mean(train_y), np.mean(test_y)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "yUOyiKvg3vMh",
        "outputId": "e2409cae-d81e-44eb-f30e-ef53169b275c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6390eee63a67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
        "test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]"
      ],
      "metadata": {
        "trusted": true,
        "id": "GhBn4Z5A3vMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertBinaryClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertBinaryClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, tokens, masks=None):\n",
        "        _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return proba"
      ],
      "metadata": {
        "trusted": true,
        "id": "u7mLBZjq3vMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ensuring that the model runs on GPU, not on CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27d3XcVl3vMm",
        "outputId": "33dbed3c-b525-4310-88d6-cd1244bd0ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_clf = BertBinaryClassifier()\n",
        "bert_clf = bert_clf.cuda()     # running BERT on CUDA_GPU"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYJ7r8LY3vMm",
        "outputId": "0b4be72a-d400-417a-aa0e-45bad33f1efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407873900/407873900 [00:06<00:00, 58293660.02B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting hyper-parameters\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 3"
      ],
      "metadata": {
        "trusted": true,
        "id": "kcjbluay3vMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e8976a1-aacf-4c6c-ec8c-3fc6a5ff431f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pycodestyle:7:1: W391 blank line at end of file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokens_tensor = torch.tensor(train_tokens_ids)\n",
        "train_y_tensor = torch.tensor(train_y.reshape(-1, 1)).float()\n",
        "\n",
        "test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
        "test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()\n",
        "\n",
        "train_masks_tensor = torch.tensor(train_masks)\n",
        "test_masks_tensor = torch.tensor(test_masks)\n",
        "\n",
        "train_dataset = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "test_dataset = TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "trusted": true,
        "id": "MhR74HmT3vMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(bert_clf.parameters(), lr=3e-6)\n",
        "\n",
        "torch.cuda.empty_cache()   # Clearing Cache space for a fresh Model run"
      ],
      "metadata": {
        "trusted": true,
        "id": "G7xMrqaD3vMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time / 60)\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "  return elapsed_mins, elapsed_secs\n",
        "\n",
        "# computes accuracy\n",
        "def binary_accuracy(preds, y):\n",
        "  #rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "  correct = (preds == y).float()\n",
        "  acc = correct.sum() / len(correct)\n",
        "  return acc\n",
        "\n",
        "# training step\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    # stats\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_f1 = 0\n",
        "    # train mode\n",
        "    model.train()\n",
        "\n",
        "    for i, batch_data in enumerate(iterator):\n",
        "        \n",
        "        if i % 50 == 1:\n",
        "            print(i / len(iterator) * 100)\n",
        "            print(f'Loss: {epoch_loss / i}, Acc: {epoch_acc / i}, F1-Score: {epoch_f1 / i}')\n",
        "\n",
        "        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "\n",
        "        logits = model(token_ids, masks)\n",
        "        rounded_preds = torch.round(logits)\n",
        "\n",
        "        loss = criterion(logits, labels)\n",
        "        acc = binary_accuracy(rounded_preds, labels)\n",
        "        f1 = f1_score(labels.detach().cpu().numpy(), rounded_preds.detach().cpu().numpy(), zero_division=0)\n",
        "\n",
        "        # stats\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        epoch_f1 += f1\n",
        "\n",
        "        log_metric(\"Train Accuracy\", acc)\n",
        "        log_metric(\"Train Loss\", loss)\n",
        "        log_metric(\"F1 Score\", f1)\n",
        "        \n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        clear_output(wait=True)\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1 / len(iterator)\n",
        "\n",
        "# evaluates the model on given iterator (either \n",
        "# train_iter, valid_iter, or test_iter)\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_f1 = 0\n",
        "    # evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for i, batch_data in enumerate(iterator):\n",
        "        \n",
        "            token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "\n",
        "            logits = bert_clf(token_ids, masks)\n",
        "\n",
        "            rounded_preds = torch.round(logits)\n",
        "            \n",
        "            loss = criterion(logits, labels)\n",
        "            acc = binary_accuracy(rounded_preds, labels)\n",
        "            f1 = f1_score(labels.detach().cpu().numpy(), rounded_preds.detach().cpu().numpy(), zero_division=0)\n",
        "\n",
        "            # stats\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "            epoch_f1 += f1\n",
        "\n",
        "            log_metric(\"Val Accuracy\", acc)\n",
        "            log_metric(\"Val Loss\", loss)\n",
        "            log_metric(\"F1 Score\", f1)\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1 / len(iterator)"
      ],
      "metadata": {
        "id": "o881w_Zi_bnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.start_run(run_name = 'Experiment 1') \n",
        "\n",
        "# run tracking UI in the background\n",
        "get_ipython().system_raw(\"mlflow ui --port 5000 &\") # run tracking UI in the background\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting the authtoken (optional)\n",
        "# Get your authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = getpass('Enter the ngrok authtoken: ')  #2F7eonHHvXFgOXU0vnRJllaq0Kc_qEmuN78R6Be1v9SiSwuv\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRySEhod_Ifq",
        "outputId": "012a94e4-0436-4db0-cd94-5944b44d2517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the ngrok authtoken: ··········\n",
            "MLflow Tracking UI: https://d10d-35-221-10-160.ngrok.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion =  nn.BCELoss().to(device)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        " \n",
        "    # start time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # train for an epoch\n",
        "    train_loss, train_acc, train_f1 = train(bert_clf, train_dataloader, optimizer, criterion)\n",
        "    valid_loss, valid_acc, valid_f1 = evaluate(bert_clf, test_dataloader, criterion)\n",
        "    # end time\n",
        "    end_time = time.time()\n",
        "    # stats\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    # save model if has validation loss\n",
        "    # better than last one\n",
        "    if valid_loss < best_val_loss:\n",
        "        best_val_loss = valid_loss\n",
        "        torch.save(bert_clf.state_dict(), 'model.pt')\n",
        "        log_artifact('model.pt')\n",
        "    # stats\n",
        "    print(f'Epoch: {epoch:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Train F1-Score: {train_f1:.2f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% | Val. F1-Score: {valid_f1:.2f}')\n",
        "\n",
        "# Test\n",
        "# model.load_state_dict(torch.load('model.pt'))\n",
        "# test_loss, test_acc = evaluate(model, test_iter, criterion)\n",
        "# print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-asvn-Pp_024",
        "outputId": "44f1dfa7-f240-438f-9e47-1b6bb374945d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99.21600000000001\n",
            "Loss: 0.2590061287888689, Acc: 0.9405337848734076, F1-Score: 0.8681718002472804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.end_run()"
      ],
      "metadata": {
        "id": "6OLU5FAwE9U1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}